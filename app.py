import os
import re
import time
import random
import datetime
from typing import List, Optional, Dict, Tuple

import pandas as pd
import streamlit as st
from pydantic import BaseModel, Field

from google import genai
from google.genai import types
from google.genai import errors as genai_errors


# =========================
# API KEYï¼ˆç›´æ›¸ãç¦æ­¢ï¼‰
# =========================
def load_api_key() -> Optional[str]:
    try:
        key = st.secrets.get("GEMINI_API_KEY", None)
    except Exception:
        key = None
    return key or os.environ.get("GEMINI_API_KEY")


API_KEY = load_api_key()
if not API_KEY:
    st.error("APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚.streamlit/secrets.toml ã‹ ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()


@st.cache_resource
def get_client():
    return genai.Client(api_key=API_KEY)


# =========================
# Structured Output schema
# =========================
class HorsePick(BaseModel):
    é¦¬å: str
    äººæ°—æƒ³å®š: Optional[str] = None
    è©•ä¾¡: str = Field(description="S/A/B/C ã®ã„ãšã‚Œã‹")

    èƒ½åŠ›: int = Field(ge=0, le=100)
    é©æ€§: int = Field(ge=0, le=100)
    å±•é–‹: int = Field(ge=0, le=100)
    èª¿å­: int = Field(ge=0, le=100)
    ä¸ç¢ºå®Ÿæ€§: int = Field(ge=0, le=100, description="é«˜ã„ã»ã©æƒ…å ±ä¸è¶³")

    æ€è€ƒã«ã‚ˆã‚‹åˆ†æçµæœ: str
    æ‡¸å¿µç‚¹: str


class PredictionResult(BaseModel):
    picks: List[HorsePick]


# =========================
# Helpersï¼ˆãƒ­ã‚°ã¯å‡ºã•ãªã„ï¼‰
# =========================
def parse_retry_seconds(e: Exception) -> Optional[float]:
    s = str(e)
    m = re.search(r"Please retry in ([0-9.]+)s", s)
    if m:
        return float(m.group(1))
    m = re.search(r"'retryDelay': '([0-9.]+)s'", s)
    if m:
        return float(m.group(1))
    return None


def is_quota_zero_message(e: Exception) -> bool:
    s = str(e)
    return ("limit: 0" in s) and ("Quota exceeded" in s)


def sleep_with_timer(total: float, update_time_cb):
    """å¾…æ©Ÿä¸­ã‚‚çµŒéæ™‚é–“è¡¨ç¤ºã ã‘ã¯æ›´æ–°ã™ã‚‹ï¼ˆãƒ­ã‚°ã¯å‡ºã•ãªã„ï¼‰"""
    remaining = max(0.0, float(total))
    while remaining > 0:
        update_time_cb()
        step = 1.0 if remaining > 1.0 else remaining
        time.sleep(step)
        remaining -= step


def call_with_retry(fn, update_time_cb, max_attempts=6, base_sleep=0.8, max_sleep=20.0):
    """
    503/429ãªã©ä¸€æ™‚ã‚¨ãƒ©ãƒ¼ã«å¼·ã„ãƒªãƒˆãƒ©ã‚¤ï¼ˆretryDelayå„ªå…ˆï¼‰
    â€»ãƒ­ã‚°ã¯è¡¨ç¤ºã—ãªã„
    """
    for attempt in range(1, max_attempts + 1):
        update_time_cb()
        try:
            return fn()

        except (genai_errors.ServerError, genai_errors.ClientError) as e:
            msg = str(e)

            retryable = (
                "503" in msg or "UNAVAILABLE" in msg
                or "429" in msg or "RESOURCE_EXHAUSTED" in msg
            )

            if (not retryable) or attempt == max_attempts:
                raise

            delay = parse_retry_seconds(e)
            if delay is not None:
                sleep = min(max_sleep, delay + random.random())
            else:
                sleep = min(max_sleep, base_sleep * (2 ** (attempt - 1)))
                sleep *= (0.7 + 0.6 * random.random())

            sleep_with_timer(sleep, update_time_cb)


def extract_sources_from_response(response) -> List[dict]:
    sources = []
    try:
        cand = response.candidates[0]
        gm = getattr(cand, "grounding_metadata", None)
        if not gm:
            return sources
        chunks = getattr(gm, "grounding_chunks", None) or []
        for ch in chunks:
            web = getattr(ch, "web", None)
            if web and getattr(web, "uri", None):
                title = getattr(web, "title", None) or web.uri
                sources.append({"title": title, "uri": web.uri})
    except Exception:
        pass
    return sources


def normalize_weights(w: Dict[str, float]) -> Dict[str, float]:
    s = sum(w.values())
    if s <= 0:
        n = len(w)
        return {k: 1.0 / n for k in w}
    return {k: v / s for k, v in w.items()}


def compute_total_score(p: HorsePick, w: Dict[str, float]) -> float:
    return (
        w["èƒ½åŠ›"] * p.èƒ½åŠ›
        + w["é©æ€§"] * p.é©æ€§
        + w["å±•é–‹"] * p.å±•é–‹
        + w["èª¿å­"] * p.èª¿å­
        + w["ç¢ºåº¦"] * (100 - p.ä¸ç¢ºå®Ÿæ€§)
    )


def make_bets(df_ranked: pd.DataFrame, ticket_type: str, budget_yen: int) -> pd.DataFrame:
    if budget_yen <= 0 or df_ranked.empty:
        return pd.DataFrame(columns=["åˆ¸ç¨®", "è²·ã„ç›®", "é‡‘é¡(å††)"])

    top = df_ranked["é¦¬å"].tolist()
    unit = 100

    def split_amount(total: int, k: int) -> List[int]:
        total = (total // unit) * unit
        if k <= 0 or total <= 0:
            return []
        base = (total // k // unit) * unit
        amounts = [base] * k
        rem = total - base * k
        i = 0
        while rem >= unit and i < k:
            amounts[i] += unit
            rem -= unit
            i += 1
        return amounts

    bets = []

    if ticket_type in ["é¦¬é€£", "ãƒ¯ã‚¤ãƒ‰", "é¦¬å˜"]:
        if len(top) >= 2:
            axis = top[0]
            opp = top[1:4]  # æœ€å¤§3ç‚¹
            if ticket_type == "é¦¬å˜":
                combos = [f"{axis} â†’ {o}" for o in opp]
            else:
                combos = [f"{axis} - {o}" for o in opp]
            amts = split_amount(budget_yen, len(combos))
            for c, a in zip(combos, amts):
                bets.append({"åˆ¸ç¨®": ticket_type, "è²·ã„ç›®": c, "é‡‘é¡(å††)": a})

    elif ticket_type == "å˜å‹":
        amts = split_amount(budget_yen, 1)
        bets.append({"åˆ¸ç¨®": "å˜å‹", "è²·ã„ç›®": top[0], "é‡‘é¡(å††)": amts[0] if amts else 0})

    elif ticket_type == "è¤‡å‹":
        k = min(2, len(top))
        combos = top[:k]
        amts = split_amount(budget_yen, k)
        for c, a in zip(combos, amts):
            bets.append({"åˆ¸ç¨®": "è¤‡å‹", "è²·ã„ç›®": c, "é‡‘é¡(å††)": a})

    elif ticket_type == "ä¸‰é€£è¤‡":
        if len(top) >= 3:
            a, b = top[0], top[1]
            combos = [f"{a} - {b} - {c}" for c in top[2:5]]  # æœ€å¤§3ç‚¹
            amts = split_amount(budget_yen, len(combos))
            for c, aamt in zip(combos, amts):
                bets.append({"åˆ¸ç¨®": "ä¸‰é€£è¤‡", "è²·ã„ç›®": c, "é‡‘é¡(å††)": aamt})

    elif ticket_type == "ä¸‰é€£å˜":
        if len(top) >= 3:
            a, b = top[0], top[1]
            combos = [f"{a} â†’ {b} â†’ {c}" for c in top[2:5]]  # æœ€å¤§3ç‚¹
            amts = split_amount(budget_yen, len(combos))
            for c, aamt in zip(combos, amts):
                bets.append({"åˆ¸ç¨®": "ä¸‰é€£å˜", "è²·ã„ç›®": c, "é‡‘é¡(å††)": aamt})

    return pd.DataFrame(bets)


# =========================
# Core: Search -> JSON (2-step)
# =========================
MODEL_CANDIDATES = [
    "gemini-2.5-flash",
    "gemini-2.0-flash",
]

def run_prediction(query: str, weights: Dict[str, float], force_refresh: bool, update_time_cb) -> Tuple[pd.DataFrame, List[dict]]:
    client = get_client()

    # åŒä¸€ã‚¯ã‚¨ãƒªã®æ¤œç´¢ãƒ¡ãƒ¢ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿æŒï¼ˆå®‰å®šé‹ç”¨UIã¯å‡ºã•ãªã„ãŒã€å†…éƒ¨ã§ç„¡é§„æ‰“ã¡ã‚’æ¸›ã‚‰ã™ï¼‰
    st.session_state.setdefault("memo_cache", {})
    memo_cache: Dict[str, dict] = st.session_state["memo_cache"]

    memo = None
    sources: List[dict] = []

    if (not force_refresh) and (query in memo_cache):
        memo = memo_cache[query]["memo"]
        sources = memo_cache[query]["sources"]

    # Step1: æ¤œç´¢ï¼ˆtoolsã‚ã‚Šï¼‰
    if memo is None:
        prompt_research = f"""
ã‚ãªãŸã¯è«–ç†çš„ãªç«¶é¦¬åˆ†æå®˜ã§ã™ã€‚
Googleæ¤œç´¢ï¼ˆæœ€æ–°æƒ…å ±ï¼‰ã‚’ä½¿ã£ã¦ã€æ¬¡ã®ãƒ¬ãƒ¼ã‚¹ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ã€å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ã€‘
{query}

æ³¨æ„ï¼š
- ãƒ¬ãƒ¼ã‚¹åãŒä¸æ˜ã§ã‚‚ã€æ—¥ä»˜ãƒ»ç«¶é¦¬å ´ãƒ»Rç•ªå·ãŒä¸€è‡´ã™ã‚‹ãƒ¬ãƒ¼ã‚¹ã‚’å¯¾è±¡ã«ã—ã¦ãã ã•ã„ã€‚

æ¬¡ã‚’å¿…ãšå«ã‚ã¦ã€ç®‡æ¡æ›¸ãä¸­å¿ƒã§æ•´ç†ã—ã¦ãã ã•ã„ï¼š
- ãƒ¬ãƒ¼ã‚¹æ¡ä»¶ï¼ˆå¤©æ°—ãƒ»é¦¬å ´ãƒ»ã‚³ãƒ¼ã‚¹å‚¾å‘ãƒ»æ ã®å‚¾å‘ï¼‰
- å‡ºèµ°é¦¬ï¼ˆæœ‰åŠ›é¦¬å€™è£œï¼‰ã¨æ ¹æ‹ 
- å±•é–‹æƒ³å®šï¼ˆãƒšãƒ¼ã‚¹ã€è„šè³ªåˆ†å¸ƒï¼‰
- çŠ¶æ…‹é¢ï¼ˆèª¿æ•™/é¦¬ä½“é‡/ã‚³ãƒ¡ãƒ³ãƒˆç­‰ãŒå–ã‚Œã‚Œã°ï¼‰
- æƒ…å ±ä¸è¶³ãƒ»ä¸ç¢ºå®Ÿæ€§ï¼ˆå–ã‚Œãªã„æƒ…å ±ã¯æ˜ç¤ºï¼‰
"""

        grounding_tool = types.Tool(google_search=types.GoogleSearch())
        cfg1 = types.GenerateContentConfig(tools=[grounding_tool], temperature=0.3)

        last_err = None
        for mn in MODEL_CANDIDATES:
            try:
                resp1 = call_with_retry(
                    lambda: client.models.generate_content(
                        model=mn,
                        contents=prompt_research,
                        config=cfg1,
                    ),
                    update_time_cb=update_time_cb,
                )
                memo = resp1.text
                sources = extract_sources_from_response(resp1)
                memo_cache[query] = {"memo": memo, "sources": sources}
                break
            except Exception as e:
                last_err = e
                continue

        if memo is None:
            raise last_err

    # Step2: JSONæ•´å½¢ï¼ˆtoolsãªã—ï¼‰
    prompt_format = f"""
æ¬¡ã®åˆ†æãƒ¡ãƒ¢ã‚’ã‚‚ã¨ã«ã€æœ‰åŠ›é¦¬ã‚’5ã€œ6é ­ã«çµã£ã¦çµè«–ã‚’å‡ºã—ã¦ãã ã•ã„ã€‚

ã€å‡ºåŠ›è¦ä»¶ã€‘
- å‡ºåŠ›ã¯å¿…ãš JSON ã®ã¿ï¼ˆJSONä»¥å¤–ã®æ–‡å­—ã¯ç¦æ­¢ï¼‰
- ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã¯æ¬¡ã®å½¢ï¼š
  {{ "picks": [ ... ] }}
- è©•ä¾¡ã¯ S/A/B/C ã®ã„ãšã‚Œã‹
- å„ã‚¹ã‚³ã‚¢ã¯æ•´æ•°ã§ 0ã€œ100
- ä¸ç¢ºå®Ÿæ€§ã¯é«˜ã„ã»ã©æƒ…å ±ä¸è¶³
- ã‚³ãƒ¡ãƒ³ãƒˆã¯2ã€œ5æ–‡ã§ç°¡æ½”ã«

ã€åˆ†æãƒ¡ãƒ¢ã€‘
{memo}
"""

    cfg2 = types.GenerateContentConfig(
        response_mime_type="application/json",
        response_json_schema=PredictionResult.model_json_schema(),
        temperature=0.2,
    )

    last_err2 = None
    result: Optional[PredictionResult] = None

    for mn in MODEL_CANDIDATES:
        try:
            resp2 = call_with_retry(
                lambda: client.models.generate_content(
                    model=mn,
                    contents=prompt_format,
                    config=cfg2,
                ),
                update_time_cb=update_time_cb,
            )
            result = PredictionResult.model_validate_json(resp2.text)
            break
        except Exception as e:
            last_err2 = e
            continue

    if result is None:
        raise last_err2

    df = pd.DataFrame([p.model_dump() for p in result.picks])
    df["ç·åˆç‚¹"] = [round(compute_total_score(p, weights), 1) for p in result.picks]
    df = df.sort_values(by="ç·åˆç‚¹", ascending=False).reset_index(drop=True)

    return df, sources


# =========================
# UI
# =========================
st.set_page_config(page_title="AIç«¶é¦¬äºˆæƒ³", layout="wide")
st.title("ğŸ AIç«¶é¦¬äºˆæƒ³ï¼ˆã‹ã‚“ãŸã‚“ï¼‰")
st.caption("æ—¥ä»˜ãƒ»ç«¶é¦¬å ´ãƒ»Rç•ªå·ã‚’é¸ã‚“ã§æŠ¼ã™ã ã‘ã€‚é‡è¦–ãƒã‚¤ãƒ³ãƒˆã ã‘èª¿æ•´ã§ãã¾ã™ã€‚ãƒ­ã‚°ã¯è¡¨ç¤ºã—ã¾ã›ã‚“ã€‚")

with st.sidebar:
    st.header("ãƒ¬ãƒ¼ã‚¹å…¥åŠ›")
    race_date = st.date_input("æ—¥ä»˜", value=datetime.date.today())

    places = ["ä¸­å±±", "é˜ªç¥", "æ±äº¬", "äº¬éƒ½", "ä¸­äº¬", "å°å€‰", "æ–°æ½Ÿ", "ç¦å³¶", "æœ­å¹Œ", "å‡½é¤¨", "å¤§äº•", "å·å´"]
    place = st.selectbox("ç«¶é¦¬å ´", places)

    race_num = st.number_input("ãƒ¬ãƒ¼ã‚¹ç•ªå· (R)", min_value=1, max_value=12, value=11)

    st.divider()
    st.header("é‡è¦–ãƒã‚¤ãƒ³ãƒˆï¼ˆåˆè¨ˆã¯è‡ªå‹•èª¿æ•´ï¼‰")
    w_ability = st.slider("èƒ½åŠ›ï¼ˆå®Ÿç¸¾ãƒ»ã‚¯ãƒ©ã‚¹ï¼‰", 0, 100, 40, 1)
    w_fit = st.slider("é©æ€§ï¼ˆè·é›¢ãƒ»é¦¬å ´ãƒ»ã‚³ãƒ¼ã‚¹ï¼‰", 0, 100, 25, 1)
    w_pace = st.slider("å±•é–‹ï¼ˆè„šè³ªãƒ»ãƒšãƒ¼ã‚¹ï¼‰", 0, 100, 20, 1)
    w_form = st.slider("èª¿å­ï¼ˆèª¿æ•™ãƒ»æ°—é…ï¼‰", 0, 100, 15, 1)
    w_cert = st.slider("ç¢ºåº¦ï¼ˆæƒ…å ±ãŒæƒã£ã¦ã„ã‚‹ã‹ï¼‰", 0, 100, 20, 1)

    st.divider()
    st.header("è²·ã„ç›®ï¼ˆä»»æ„ï¼‰")
    ticket_type = st.selectbox("åˆ¸ç¨®", ["é¦¬é€£", "ãƒ¯ã‚¤ãƒ‰", "é¦¬å˜", "ä¸‰é€£è¤‡", "ä¸‰é€£å˜", "å˜å‹", "è¤‡å‹"], index=0)
    budget_yen = st.number_input("äºˆç®—ï¼ˆå††ï¼‰", min_value=0, step=100, value=1000)

    # åˆå¿ƒè€…å‘ã‘ï¼šå¿…è¦ãªã¨ãã ã‘æ›´æ–°
    force_refresh = st.checkbox("æœ€æ–°æƒ…å ±ã§å†æ¤œç´¢ã™ã‚‹ï¼ˆå¿…è¦ãªã¨ãã ã‘ï¼‰", value=False)

    run_btn = st.button("AIäºˆæƒ³ã‚’ä½œæˆ", type="primary")


if run_btn:
    date_str = race_date.strftime("%Yå¹´%mæœˆ%dæ—¥")
    rn = f"{race_num}R"
    query = f"{date_str} {place}ç«¶é¦¬å ´ {rn} å‡ºé¦¬è¡¨ äºˆæƒ³".strip()

    st.subheader(f"ğŸ¯ å¯¾è±¡: {date_str} {place} {rn}")

    weights = normalize_weights({
        "èƒ½åŠ›": float(w_ability),
        "é©æ€§": float(w_fit),
        "å±•é–‹": float(w_pace),
        "èª¿å­": float(w_form),
        "ç¢ºåº¦": float(w_cert),
    })

    # çµŒéæ™‚é–“è¡¨ç¤ºï¼ˆãƒ­ã‚°ã®ä»£ã‚ã‚Šï¼‰
    time_box = st.empty()
    start = time.perf_counter()

    def update_time():
        elapsed = time.perf_counter() - start
        time_box.info(f"â± çµŒéæ™‚é–“: {elapsed:.1f} ç§’")

    update_time()

    try:
        with st.spinner("AIãŒæƒ…å ±åé›†ãƒ»åˆ†æã—ã¦ã„ã¾ã™â€¦"):
            df, sources = run_prediction(
                query=query,
                weights=weights,
                force_refresh=force_refresh,
                update_time_cb=update_time,
            )

        elapsed = time.perf_counter() - start
        time_box.success(f"âœ… å®Œäº†ï¼ ã‹ã‹ã£ãŸæ™‚é–“: {elapsed:.1f} ç§’")

        st.success("äºˆæƒ³ã‚’ä½œæˆã—ã¾ã—ãŸï¼")

        st.markdown("### ğŸ“Š æœ‰åŠ›é¦¬ï¼ˆ5ã€œ6é ­ï¼‰")
        show_cols = [
            "é¦¬å", "è©•ä¾¡", "ç·åˆç‚¹", "äººæ°—æƒ³å®š",
            "èƒ½åŠ›", "é©æ€§", "å±•é–‹", "èª¿å­", "ä¸ç¢ºå®Ÿæ€§",
            "æ€è€ƒã«ã‚ˆã‚‹åˆ†æçµæœ", "æ‡¸å¿µç‚¹"
        ]
        st.dataframe(df[show_cols], use_container_width=True)

        st.markdown("---")
        st.markdown("### ğŸ’° è²·ã„ç›®ï¼ˆå‚è€ƒï¼‰")
        bets_df = make_bets(df_ranked=df, ticket_type=ticket_type, budget_yen=int(budget_yen))
        if bets_df.empty:
            st.info("è²·ã„ç›®ã¯æœªä½œæˆã§ã™ï¼ˆäºˆç®—0å†† or ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰ã€‚")
        else:
            st.dataframe(bets_df, use_container_width=True)

        st.markdown("---")
        st.markdown("### ğŸ” å‚è€ƒã‚½ãƒ¼ã‚¹ï¼ˆå–å¾—ã§ããŸå ´åˆï¼‰")
        if sources:
            seen = set()
            uniq = []
            for s in sources:
                u = s.get("uri")
                if u and u not in seen:
                    seen.add(u)
                    uniq.append(s)
            for s in uniq[:10]:
                st.write(f"- {s.get('title','')}: {s.get('uri','')}")
        else:
            st.caption("ã‚½ãƒ¼ã‚¹ãŒå–å¾—ã§ããªã„å ´åˆã‚‚ã‚ã‚Šã¾ã™ã€‚")

    except genai_errors.ClientError as e:
        elapsed = time.perf_counter() - start
        time_box.error(f"âœ– å¤±æ•—ï¼ˆ{elapsed:.1f} ç§’ï¼‰")

        if is_quota_zero_message(e):
            st.error("Gemini API ã®åˆ©ç”¨æ ãŒ 0 ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆBilling/ãƒ—ãƒ©ãƒ³è¨­å®šï¼‰ã€‚Googleå´ã®ä½¿ç”¨çŠ¶æ³ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            wait = parse_retry_seconds(e)
            if wait is not None:
                st.error(f"åˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{int(wait)}ç§’ã»ã©å¾…ã£ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            else:
                st.error(f"APIã‚¨ãƒ©ãƒ¼: {e}")

        st.exception(e)

    except Exception as e:
        elapsed = time.perf_counter() - start
        time_box.error(f"âœ– å¤±æ•—ï¼ˆ{elapsed:.1f} ç§’ï¼‰")
        st.error("äºˆæƒ³ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ™‚é–“ã‚’ãŠã„ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        st.exception(e)

else:
    st.info("å·¦ã®å…¥åŠ›ã‚’åŸ‹ã‚ã¦ã€ŒAIäºˆæƒ³ã‚’ä½œæˆã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
